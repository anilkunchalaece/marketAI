# -*- coding: utf-8 -*-
"""MNISTKeras.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1paUmMTA4nmBzhwu8RQx-E3RVZi7fjrlv

Author : Kunchala Anil

Email : anilkunchalaece@gmail.com

Date : Feb 13 2019

Classic MNIST example using tensorflow keras
"""

#import numpy and tensorflow
import numpy as np
import tensorflow as tf

from dataTest import loadData

# check the versions of tensorflow and keras
print("tensorflow version is {}".format(tf.__version__))
print("keras version is {}".format(tf.keras.__version__))

# load data
data = loadData()
train_gen , val_gen , test_gen = data.getGenerators()



#Define Keras Trainning and Networking parameters
NB_EPOCH = 100
BATCH_SIZE = 20
VERBOSE = 1 # tf verbose level
NB_CLASSES = 15 # Number of outputs i.e 10 for MNIST
# VALIDATION_SPLIT = 0.2 # Validataion data within the training data

#load the data 
# (x_train,y_train),(x_test,y_test) = tf.keras.datasets.mnist.load_data()
#print(x_train)

#MNIST data is of 28*28 , reshape it to 784
# x_train_reshape = x_train.reshape(x_train.shape[0],x_train.shape[1]*x_train.shape[2])
# x_test_reshape = x_test.reshape(x_test.shape[0],x_test.shape[1]*x_test.shape[2])

# print("x_train reshaped from {} to {}".format(x_train.shape,x_train_reshape.shape))
# print("x_test reshaped from {} to {}".format(x_test.shape,x_test_reshape.shape))

# Normalize the train and test data

# print("range of values for x_train before normalization is between {} to {}".format(np.max(x_train_reshape),np.min(x_train_reshape)))
# print("range of values for x_test before normalization is between {} to {}".format(np.max(x_test_reshape),np.min(x_test_reshape)))

# x_train_reshape_normalized = x_train_reshape / np.max(x_train_reshape)
# x_test_reshape_normalized = x_test_reshape /np.max(x_test_reshape)

# print("range of values for x_train after normalization is between {} to {}".format(np.max(x_train_reshape_normalized),np.min(x_train_reshape_normalized)))
# print("range of values for x_test after normalization is between {} to {}".format(np.max(x_test_reshape_normalized),np.min(x_test_reshape_normalized)))

# Convert lables into one hot encoded categerial class metrics

# y_train = tf.keras.utils.to_categorical(y_train,NB_CLASSES)
# y_test = tf.keras.utils.to_categorical(y_test,NB_CLASSES)

# print(y_test[0])

#build the model

model = tf.keras.Sequential()
model.add(tf.keras.layers.Dense(32,input_shape=(10000,),activation='relu'))
model.add(tf.keras.layers.Dropout(0.2))
model.add(tf.keras.layers.Dense(32,activation='relu'))
model.add(tf.keras.layers.Dropout(0.1))
model.add(tf.keras.layers.Dense(NB_CLASSES,input_shape=(784,),activation='softmax'))

model.summary()

# Compile the model
model.compile(loss="categorical_crossentropy",optimizer="adam",metrics=['accuracy'])

STEP_SIZE_TRAIN=train_gen.n//train_gen.batch_size
STEP_SIZE_VALID=val_gen.n//val_gen.batch_size
model.fit_generator(generator=train_gen,
                    steps_per_epoch=STEP_SIZE_TRAIN,
                    validation_data=val_gen,
                    validation_steps=STEP_SIZE_VALID,
                    epochs=NB_EPOCH
)



# Evaluate a models
score = model.evaluate_generator(generator=val_gen)

print("test score {} ".format(score[0]))
print("test accuracy {}".format(score[1]))